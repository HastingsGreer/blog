@def title="By Construction ICON, progressive training vs ent to end"


# By Construction ICON

if we build an network that is inverse consistent by construction, then penalize it with the ICON error, how regularized is it? Does it become regularized by adding in noise?

\begin{align}
 v(x) &= N_\theta^{AB}(x) - N_\theta^{BA}(x) \\
 \frac{\partial}{\partial t} \Phi^{AB}(x, t) &= v(x)\\
 \Phi^{AB}(x, 0) &= x \\
 \Phi^{AB}(x) &= \Phi^{AB}(x, 1)
\end{align}


[notebook for byconstructionICON](https://colab.research.google.com/drive/1fPt6R3ZkbMJ_ntQHUkbQElhjQm9Z7Wax?usp=sharing)

results depend heavily on loss

Blurred SSD ConstICON

\fig{blurredssd.png}

Blurred SSD NoReg

\fig{blurredssdnoreg.png}

SSD ConstICON

\fig{ssdconsticon.png.png}

SSD\_only\_interpolated\_consticon

\fig{ssd_only_interpolated_consticon.png}

