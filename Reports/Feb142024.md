@def title=""


It appears that instead of regularizing the transformer with diffusion and the rest with gradICON, it's better to regularize everything with diffusion for the first few steps and everything with gradICON thereafter. This means a slightly more complex training procedure but nothing too bad.



Comparison datasets:

Lung: no change since last meeting.

Abdomen: Some images in the training dataset are upsidedown, which makes registering them harder. I need to either make my network fully equivariant to rotation or fix the dataset. The diffusion regularized approach made full equivariance a hopeless dream, but this is now maybe feasible. However I should not be lazy and fix the dataset.

I have trained equicon and ConstrICON on the defective dataset and they score 

equicon: .40

ConstrICON: .36

but who knows what that means.


IXI brain: I have keymorph running using downloaded weights. I need to replicate their synthseg labels to fully replicate their paper, after which I can run EasyReg, ANTs, and our approach on this dataset. I plan to also use KeyMorph's DLIR baseline if keymorph's registration performance replicates.

I have our approach training on the IXI dataset with the KeyMorph preprocessing.




Theoretical interest in using GradICON end to end:

Assumption, $\Phi$ is inverse consistent

$\Psi$ is inverse Consistent

what is the inverse consistency loss?

$$ TwoStep[\Phi, \Psi](A, B) \circ Twostep[\Phi, \Psi](B, A) - id$$

$$ \Phi(A, B) \circ \Psi(A \circ \Phi(A, B), B) \circ \Phi(B, A) \circ \Psi(B \circ \Phi(B, A), A) - id $$

Now, what if $\Psi$ is U, U equivariant to the class of transforms that $\Phi$ can output?


$$ \Phi(A, B) \circ \Psi(A \circ \Phi(A, B) , B \circ \Phi(A, B)^{-1} \circ \Phi(A, B)) \circ \Phi(B, A) \circ \Psi(B \circ \Phi(B, A), A) - id $$

$$ \Phi(A, B) \circ \Phi(A, B) ^{-1} \circ \Psi(A, B \circ \Phi(A, B)^{-1}) \circ \Phi(A, B) \circ \Phi(B, A) \circ \Psi(B \circ \Phi(B, A), A) - id $$
$$ \Psi(A, B \circ \Phi(A, B)^{-1}) \circ \Psi(B \circ \Phi(B, A), A) - id $$

$$ = 0$$

So, the inverse consistency loss is zero if $\Psi$ is U, U equivariant, which is the exact condition needed for the whole thing to be W, U equivariant.





