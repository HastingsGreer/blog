<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="https://apj.hgreer.com/blog"> <link rel=icon  href="/assets/favicon.png"> <title>Post ECCV Research Agenda</title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <!-- <li><a href="/FeatureMapICON/">Feature Map Inverse Consistency</a> --> <li><a href="/HatTile/">Aperiodic Tiling with Z3</a> <!-- <li><a href="/ICON/">Inverse Consistent Regstration</a> <li><a href="/Mandelbrot/">Mandelbrot Set Adventures</a> --> <li><a href="/JavascriptMandelbrot/">Mandelbrot Set</a> <li><a href="/TrebuchetSimulator/">Trebuchet Simulator</a> <li><a href="/BadMatrixMultiply/">Bad Matrix Multiplication</a> <li><a href="/GameJam/">Game Jam Games</a> <li><a href="/menu3/">Tags</a> </ul> </div> <div id=main > <div class=franklin-content ><h1 id=carl_questions ><a href="#carl_questions" class=header-anchor >CARL questions</a></h1> <p>Why is there a performance regression when training gradicon using the venv set up for CARL?</p> <ul> <li><p>Is it a pytorch version issue?</p> <li><p>Is it an icon&#95;registration version issue?</p> <li><p>Does it affect CARL training performance too?</p> </ul> <p>Can we train CARL using 16 bit attention? This should ameliorate training time</p> <p>Can we train CARL using slightly smaller resolution for the transformer? Also good for training time</p> <p>Can CARL work with a spherical harmonic / Group convolution encoder?</p> <ul> <li><p>preliminary results: no https://colab.research.google.com/drive/1C04yejs2F9v1UseygRtDaAvxWK5gvM1l?usp&#61;sharing</p> </ul> <p>How does CARL perform on Learn2reg abdomen?</p> <p>Does nonuniform spacing help?</p> <p>IXI skull strip</p> <h2 id=how_to_save_the_carl_paper ><a href="#how_to_save_the_carl_paper" class=header-anchor >How to save the CARL paper</a></h2> <p>Easiest route: get equivariance to rotations working. now we have a differentiator.</p> <p>Add more power to the encoder: The 3-D encoder has much fewer parameters than 3D tallUNet2, while the 2D encoder has the same number of parameters.</p> <h1 id=things_hastings_wants_to_do_with_unigradicon ><a href="#things_hastings_wants_to_do_with_unigradicon" class=header-anchor >Things Hastings wants to do with UniGRADICON</a></h1> <h2 id=unigradicon_dataset_20 ><a href="#unigradicon_dataset_20" class=header-anchor >UniGRADICON dataset 2.0</a></h2> <p>Add more diverse datasets:</p> <ul> <li><p>add abdomen1k dataset to training &#40;this is pure upside&#41;</p> <li><p>abdomen8k dataset?</p> <li><p>add COPDGene inter-subject </p> <li><p>add a bunch of brain datasets to training, including registration between them &#40;IXI &#43; HCP &#43; OASIS&#41;</p> <li><p>add mouse brain dataset to training</p> <li><p>using high resolution subset of Abdomen1K and COPDGene, add cropped regions to training &#40;cropped to heart, cropped to liver, cropped to pancreas&#41; </p> <li><p>SynthMorph dataset?</p> <li><p>SynthMorph dataset built from abdomen segmentations?</p> </ul> <p>Augment all datasets with</p> <ul> <li><p>All 90 degree rotations &#40;matched&#41;</p> <li><p>Random crop</p> <li><p>With and without masking. When registering a masked image to an unmasked image, compute similarity on unmasked to unmasked</p> <li><p>Add dice loss wherever we have it</p> <li><p>intensity -&gt; -intensity, &#40;2 * intensity - 1&#41;^2, intensity / 2</p> <li><p>Crop off bottom and top of image by random black rectangles</p> </ul> <p>Whenever perfoming augmentation, compute similarity on unaugmented image</p> <h2 id=ablate_architecture_of_unigradicon ><a href="#ablate_architecture_of_unigradicon" class=header-anchor >Ablate architecture of UniGRADICON</a></h2> <p>Once we have all that, it&#39;s just GPU time to train a bunch of architectures on it</p> <p>CARL, ConstrICON, GradICON, ConstrICON / GradICON hybrid</p> <p>Possibility One:</p> <p>add some constricon affine </p> <h1 id=infrastructure_todo ><a href="#infrastructure_todo" class=header-anchor >Infrastructure TODO</a></h1> <p>we want </p> <pre><code class="bash hljs">pip install unigradicon

unigradicon register --fixed=squirrel_jawbone.nrrd --moving=aardvark_jawbone.nrrd --transform_out=transform.nrrd

unigradicon warp --nearest --moving=aardvark_segmentation.nrrd --image_out=warped_jawbone.nrrd</code></pre> <p>and we can finally produce this.</p> <p>Also, icon&#95;registration should have a built in learn2reg interface along with the itk interface if we&#39;re going to keep participating in these contests.</p> <a href=/Reports/>Back to Reports</a> <div class=page-foot > <div> <a href=https://subdavis.com>subdavis.com </a> <a href=http://forrestli.con>forrestli.com</a> <div class=copyright > &copy; Hastings Greer. Last modified: February 24, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div>