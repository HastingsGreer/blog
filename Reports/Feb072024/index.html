<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="https://apj.hgreer.com/blog"> <link rel=icon  href="/assets/favicon.png"> <title></title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <!-- <li><a href="/FeatureMapICON/">Feature Map Inverse Consistency</a> --> <li><a href="/HatTile/">Aperiodic Tiling with Z3</a> <!-- <li><a href="/ICON/">Inverse Consistent Regstration</a> <li><a href="/Mandelbrot/">Mandelbrot Set Adventures</a> --> <li><a href="/JavascriptMandelbrot/">Mandelbrot Set</a> <li><a href="/TrebuchetSimulator/">Trebuchet Simulator</a> <li><a href="/BadMatrixMultiply/">Bad Matrix Multiplication</a> <li><a href="/GameJam/">Game Jam Games</a> <li><a href="/menu3/">Tags</a> </ul> </div> <div id=main > <div class=franklin-content ><p>Test</p> <p>Write: DICE calculation Train ConstrICON on abdomen Train GradICON on abdomen Write abdomen validation code</p> <p>Also needs ANts, voxelmorph</p> <p>This week I finally solved the intermittent NaN coming from LNCC. It came down to an issue with floating point precision differing between GPUs, which caused jensen’s inequality to be violated, allowing a square root to be taken of a negative number. Instead of increasing the epsilon value to push values further away from zero, which could be ruined y a special case or hardware change that creates larger jensen violations in the future, I wrapped the supposedly nonnegative value in a relu which should solve it permanently.</p> <p>I brought the docekr container into exact alignment with the ConstrICON paper by adjusting the data augmentation used and the batch size.</p> <p>I found a dataset to use with the equivariant registration paper, Abdomen1K. It contains 1000 completely uncurated abdomen images segmentations. Because there are a variety of framings of the abdomen in CT, this dataset has massive translation shifts, which should line up exactly with the strengths of the equivariant network and give the best chance of it demonstrating its advantages. I have split the public data into 800 train cases, 100 val cases, and 100 test cases. I am training the equivariant registration network, GradICON, and ContrICON on it. I have also evaluate ANTs registration on a subset of the validation set and found that it performs ___. This is ___ than equicon at timestep ___</p> <p>Unfortunately, this dataset has put lie to the hpppes of equicon being a “hands off no tuning” network like GradICON or ConstrICON, as this dataset is requiring a different regularization parameter to get sensible results.</p> <p>I am currently cropping / padding the images when resampling them to equal voxel spacing for training. I am not sure that this is optimal, and I’m curious to try instead resizing all images to fit exactly in 175 x 175 x 175, and letting the neural network just tolerate that its input voxels aren’t suare. I am exited to try this approach on such a raw dataset instead of having to try to un-crop/pad input abdomen images as would be necessary for other abdomen datasets I have seen.</p> <a href=/Reports/>Back to Reports</a> <div class=page-foot > <div> <a href=https://subdavis.com>subdavis.com </a> <a href=http://forrestli.con>forrestli.com</a> <div class=copyright > &copy; Hastings Greer. Last modified: August 28, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div>