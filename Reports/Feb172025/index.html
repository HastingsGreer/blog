<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="https://apj.hgreer.com/blog"> <link rel=icon  href="/assets/favicon.png"> <title></title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <!-- <li><a href="/FeatureMapICON/">Feature Map Inverse Consistency</a> --> <li><a href="/HatTile/">Aperiodic Tiling with Z3</a> <!-- <li><a href="/ICON/">Inverse Consistent Regstration</a> <li><a href="/Mandelbrot/">Mandelbrot Set Adventures</a> --> <li><a href="/JavascriptMandelbrot/">Mandelbrot Set</a> <li><a href="/TrebuchetSimulator/">Trebuchet Simulator</a> <li><a href="/BadMatrixMultiply/">Bad Matrix Multiplication</a> <li><a href="/GameJam/">Game Jam Games</a> <li><a href="/menu3/">Tags</a> </ul> </div> <div id=main > <div class=franklin-content ><h1>The Plan:</h1> <p>Two goals for new unigradicon: affine registration and multimodal registration</p> <p>Neural Affine registration approaches:</p> <p>Extract affine component from unigradicon output</p> <ul> <li><p>Appears to be impossible for complicated reasons &#40;willing to elaborate&#41;</p> </ul> <p>Large ConstrICON model</p> <ul> <li><p>Trains fine, works fine, training on new datasets nicely documented</p> <li><p>Currently in use with Basar for his KL evaluation on OAI project</p> <li><p>Doesn&#39;t generalize to images not in the uniGradICON dataset - weird</p> </ul> <p>Directly optimize affine map against LNCC</p> <ul> <li><p>Works fine, doesn&#39;t require training, generalizes</p> <li><p>Considered for Basar&#39;s project but slower than previous approach</p> <li><p>Not interesting or publishable, but a good baseline</p> </ul> <p>Directly optimize affine map prior to unigradicon</p> <ul> <li><p>Works fine, doesn&#39;t require new training, generalizes</p> <li><p>Complicated, not interested in explaining again because...</p> <li><p>Worse than previous approach &#40;RIP&#41;</p> </ul> <p>Extract affine transform from equivariant registration &#40;CARL&#41;</p> <ul> <li><p>Trains ...ok, not nicely documented yet</p> <li><p>Global capture radius, which is why we use CARL on the biobank dataset- this is a major capabilities boost</p> <li><p>uniCARL Doesn&#39;t generalize to images not in the uniGradICON dataset - weird</p> </ul> <p>Use KeyMorph architecture</p> <ul> <li><p>fundamentally can&#39;t generalize to images not in the training set.</p> <li><p>included because it emphasizes the pattern</p> </ul> <p>side project:</p> <h1>The torch unigradicon performance question</h1> <p>Investigation 1: biag-w05, 10 io iterations of unigradicon</p> <p>torch 1.19: 18.6 seconds</p> <p>torch 2.6: 17.5 seconds</p> <p>Investigation 2: biag-gpu6, 10 steps of gradicon training on noise</p> <p>torch 1.19: </p> <a href=/Reports/>Back to Reports</a> <div class=page-foot > <div> <a href=https://subdavis.com>subdavis.com </a> <a href=http://forrestli.con>forrestli.com</a> <div class=copyright > &copy; Hastings Greer. Last modified: February 19, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div>