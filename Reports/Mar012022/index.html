<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="https://apj.hgreer.com/blog"> <link rel=icon  href="/assets/favicon.png"> <title>GradICON first knee results</title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <!-- <li><a href="/FeatureMapICON/">Feature Map Inverse Consistency</a> --> <li><a href="/HatTile/">Aperiodic Tiling with Z3</a> <!-- <li><a href="/ICON/">Inverse Consistent Regstration</a> <li><a href="/Mandelbrot/">Mandelbrot Set Adventures</a> --> <li><a href="/JavascriptMandelbrot/">Mandelbrot Set</a> <li><a href="/TrebuchetSimulator/">Trebuchet Simulator</a> <li><a href="/BadMatrixMultiply/">Bad Matrix Multiplication</a> <li><a href="/GameJam/">Game Jam Games</a> <li><a href="/menu3/">Tags</a> </ul> </div> <div id=main > <div class=franklin-content ><h1 id=atlas_registration_progress ><a href="#atlas_registration_progress" class=header-anchor >Atlas registration progress</a></h1> <p>At low resolution</p> <p>Since last time, found that I could not train ICON_atlas loss to match performance of ICON on OAI knees: second step of multiscale training failed as folds ran away, lambda increased to infinity.</p> <h1 id=outreach ><a href="#outreach" class=header-anchor >Outreach:</a></h1> <p>Presenting same powerpoint from group meeting last week to funky bunch on wednesday. Several people from Kitware&#39;s AI team coming: anything I should make sure to include?</p> <h1 id=follow_up_to_new_approach_to_patchwise_registration ><a href="#follow_up_to_new_approach_to_patchwise_registration" class=header-anchor >Follow up to &quot;New approach to patchwise registration&quot;</a></h1> <p>Wanted to setup for applying <a href="https://nvlabs.github.io/instant-ngp/">Instant Neural Graphics Primitives</a> to neural registration fields. To do this, I needed a valid regularization proceedure. Started with this approach:</p> <img src="/assets/Reports/Mar012022/code/nedf.drawio.png" alt=""> <p>Which then doesn&#39;t work: produces very irregular mappings or identity map:</p> <p><a href="https://colab.research.google.com/github/HastingsGreer/InverseConsistency/blob/master/notebooks/NEDF.ipynb">colab notebook</a></p> <p>New approach: Use torch.autograd to compute spatial gradients of node &quot;Approximation of original position in Image A, - Position in Image A&quot; with respect to node &quot;Position in Image A&quot;</p> <p>Square these partial derivatives and minimize the result. This is inspired by the gradient penalty for GANS espoused in <a href="https://arxiv.org/abs/1801.04406">When do GANS actually converge</a> which we discussed a while back: Each sample forces a neighborhood around it to be near zero, instead of just a single point.</p> <p>FOR A SINGLE PAIR, THIS WORKS FOR REGISTRATION&#33;</p> <p><a href="https://colab.research.google.com/drive/1aCzG7tUwDjnlGvcUBAdSIkpVKWtuDq76?usp&#61;sharing">notebook</a></p> <p>Image A</p> <img src="/assets/Reports/Mar012022/code/nedf_A.png" alt=""> <p>Image B</p> <img src="/assets/Reports/Mar012022/code/nedf_B.png" alt=""> <p>Grid</p> <img src="/assets/Reports/Mar012022/code/grid.png" alt=""> <p>Warped B</p> <img src="/assets/Reports/Mar012022/code/nedf_warped_B.png" alt=""> <h1 id=gradienticon ><a href="#gradienticon" class=header-anchor >GradientICON</a></h1> <p>While getting the above to work, I was impressed enough with the performance of the Jacobian penalty on the Inverse Consistency term to try it back on the standard convolutional ICON.</p> <p>I computed the jacobian using finite differences instead of torch.autograd since that was more convenient, and it&#39;s only through linear interpolations, so finite differences are usually exact anyways.</p> <pre><code class="python hljs">delta = <span class=hljs-number >.001</span>

<span class=hljs-keyword >if</span> <span class=hljs-built_in >len</span>(<span class="hljs-variable language_">self</span>.identityMap.shape) == <span class=hljs-number >4</span>:
    dx = torch.Tensor([[[[delta]], [[<span class=hljs-number >0.</span>]]]]).to(config.device)
    dy = torch.Tensor([[[[<span class=hljs-number >0.</span>]], [[delta]]]]).to(config.device)
    direction_vectors = (dx, dy)

<span class=hljs-keyword >elif</span> <span class=hljs-built_in >len</span>(<span class="hljs-variable language_">self</span>.identityMap.shape) == <span class=hljs-number >5</span>:
    dx = torch.Tensor([[[[[delta]]], [[[<span class=hljs-number >0.</span>]]], [[[<span class=hljs-number >0.</span>]]]]]).to(config.device)
    dy = torch.Tensor([[[[[<span class=hljs-number >0.</span>]]], [[[delta]]], [[[<span class=hljs-number >0.</span>]]]]]).to(config.device)
    dz = torch.Tensor([[[[<span class=hljs-number >0.</span>]]], [[[<span class=hljs-number >0.</span>]]], [[[delta]]]]).to(config.device)
    direction_vectors = (dx, dy, dz)

<span class=hljs-keyword >for</span> d <span class=hljs-keyword >in</span> direction_vectors:
    approximate_Iepsilon_d = <span class="hljs-variable language_">self</span>.phi_AB(<span class="hljs-variable language_">self</span>.phi_BA(Iepsilon + d))
    inverse_consistency_error_d = Iepsilon + d - approximate_Iepsilon_d
    grad_d_icon_error = (inverse_consistency_error - inverse_consistency_error_d) / delta
    direction_losses.append(torch.mean(grad_d_icon_error**<span class=hljs-number >2</span>))

inverse_consistency_loss = <span class=hljs-built_in >sum</span>(direction_losses)</code></pre> <p>This works great in 2d, solving the hollow triangles circles benchmark in 2 minutes instead of ~ an hour, and with more reliable and higher quality final results:</p> <p><a href="https://colab.research.google.com/drive/1oVilftO41NREX-G7fBujQTu_QlB4U-QT?usp&#61;sharing">notebook</a></p> <img src="/assets/Reports/Mar012022/code/GradientICONTriangleCircles.png" alt=""> <h1 id=gradienticon_in_3d ><a href="#gradienticon_in_3d" class=header-anchor >GradientICON in 3D</a></h1> <p>Trains like a dream with not much fussing even at batch size 1, 160 x 384 x 384.</p> <p><a href="https://github.com/uncbiag/ICON/blob/c2732603a1e8e5e11c3bdebbb6f8949811769b53/notebooks/GradICONDice.ipynb">Step 1 notebook</a></p> <p>Step 1 &#40;40 x 96 x 96&#41;: DICE 66</p> <p><a href="https://github.com/uncbiag/ICON/blob/c2732603a1e8e5e11c3bdebbb6f8949811769b53/notebooks/GradICONDICEhires.ipynb">Step 2 notebook</a></p> <p>Step 2 &#40;80 x 192 x 192&#41;: DICE 71.3</p> <p><a href="https://github.com/uncbiag/ICON/blob/c2732603a1e8e5e11c3bdebbb6f8949811769b53/notebooks/GradICONDICEfullres.ipynb">Step 3 notebook</a></p> <p>Step 3 &#40;160 x 384 x 384&#41;: DICE 73.3</p> <a href=/Reports/>Back to Reports</a> <div class=page-foot > <div> <a href=https://subdavis.com>subdavis.com </a> <a href=http://forrestli.con>forrestli.com</a> <div class=copyright > &copy; Hastings Greer. Last modified: August 09, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div>