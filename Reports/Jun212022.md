## Lung results!

In all cases: 

LNCC loss with sigma=5 pixels

Augmentation: random permutation + flipping of axis + 10% affine warping.

Augmentation implemented here: [github](https://github.com/HastingsGreer/ICON_lung/blob/d1576a0131c4d7783987ee6292ed13f07113a748/triple_deformable_lung.py##L68)

Image preprocessing: clip intensity to [-1000, 0], scale to [-1, 0], shift to [0, 1], mask out lung.

Preprocessing available here: [github](https://github.com/uncbiag/ICON/blob/545fb1cac7429b35c2447a351a44f5d870917834/src/icon_registration/pretrained_models/lung_ct.py##L33)

lambda=1

On to the cases:

High resolution, no finetuning:

```
mTRE: 2.3006992213541535, mTRE_X: 0.8731911562027538, mTRE_Y: 1.1455374789234933, mTRE_Z: 1.3988634236498467, DICE: 0.9839835991734549
mTRE: 1.7353536802929188, mTRE_X: 0.6434888778122482, mTRE_Y: 0.8173537622369533, mTRE_Z: 1.0992206030662603, DICE: 0.9875824779902229
0.9839835991734549
```






# TODO

## Cleanup todo

✓ footsteps needs to log uncommitted file if that's what's being run

merge code in "/media/data/hastings/InverseConsistency/" into master

✓ get OAI pull request merged

compress OAI models by dropping identitymaps

add identitymap stripping code to ICON

ICON 1.0 release

merge biag .vimrc

put augmentation into train.py

## Ambitious todo

genius idea: registration that improves previous result: train by randomy resetting prev result

try segmenting latest kaggle challenge

try registering latest kaggle challenge

99%ICON: ICON but the worst 1% of inverse consistencies aren't penalized

mixture of gaussians ICON:
	interpret ICON as "registration outputs a gaussian at each pixel, ICON loss is log odds of exact inverse consistency. 
	in that framework, rewrite to output a mixture of gaussians instead of a gaussian: perhaps can accurately model tearing?

need a synthetic dataset for tearing.

one approach to mitigate this is to create a very diverse zoo of intensity transfer functions for data augmentation, and hope that this forces the network to learn to register a larger complete set of transfer functions including MR -> CT even though that's not a strict 1-1 function

## Marc request todo

train oai knees with LNCC + augmentation

- currently training with just LNCC for taste. Will try next with LNCC + augmentation

train lung with lin loss + augmnentation

evaluate latest highres model

put all results into the overleaf

make formal list of experiments for paper -- journal article?

put OAI preprocessing into pretrained models

Create a set of images where the shapes are bright and the background dark. Create another set where it is the other way around. Train a network that gets as inputs either a random image pair from one or from the other. Will this network entirely fail if it is presented with a pair where one image is from one set and the other one from the other?

## ITK deficiencies todo

verify whether itk can be installed on an old version yet?

get itk to not segfault when asked to save a composite transform without []ifying it

get itkDisplacementFieldJacobianFilter wrapped for doubles



 
